# 인체 미동을 이용한 공감도 평가 방법
## 요약
* 본 연구는 사회 감성(Social emotion)중 공감도 정량화 방법을 제안하고자 한다.
비접촉형 센싱 방법인 인체 미동 기술을 이용하였다.
참가자들은 공감한 그룹과 공감하지 않은 그룹으로 분류하였다.
웹캠을 이용해 표정 Task를 수행하는 동안 영상의 상반신 데이터를 수집하엿다.
수집 된 데이터는 각 주파수 성분 별로 0.5 Hz, 1 Hz, 3 Hz, 5 Hz, 15 Hz로 분류하여 추출하였다.
추출 된 데이터는 움직임의 평균과 변화량, 움직임의 동조현상을 비교하였다.
그 결과 공감한 그룹의 움직임 평균과 움직임의 변화정도가 낮게 나타났다.
공감하지 못한 그룹의 경우 평균 움직임과 변화정도가 큰 것으로 나타났으며 통계적으로 유의한 차이를 보였다.
또한 공감한 그룹의 두 피험자의 경우 표정 Task를 수행하는 동안 움직임에 동조 현상이 나타나는 것을 확인하였다.
이는 두 사람 간에 공감이 형성 되었을 때 자연스럽게 집중을 하게 되고 그에 따라 움직임에 정도가 차이가 나는 것으로 볼 수 있다.
본 연구는 비접촉 센싱 방법을 통해 공감도 측정 가능성을 확인하는데 의의가 있다.


## 1. 서론
* 최근 모바일 기기가 보편화 되면서 사물 인터넷 기반이 형성되고 있다.
SNS는 여러 모바일 디바이스를 이용해서 새롭고 다양한 형식으로 사회적 상호작용을 발생시킨다.
이에 SNS에서 발생되는 사회적인 인적 네트워크 및 관계 형성 등에 관한 연구에 관심이 증가하고 있다.
IT 기술의 발전으로 인터넷이 유선에서 무선 중심으로 변화 되었다.
무선 인터넷의 활성화로 스마트폰, 태블릿, 스마트 워치 등 사용자 중심환경으로 변화 되고 있다.
따라서 다양한 공간에서 페이스북, 트위터 등을 이용해 사회적 관계를 형성하고 있다.

* 사회적 관계는 사회적 인지(Social cognition) 또는 상호작용을 통해 형성 된다.
이는 상대방의 정신적 상태나 행동에 대하여 이해하는 것을 의미한다.
상대방을 이해하려면 상대방의 공감적 반응이 반드시 요구 된다.
이에 따라 온라인에서 발생하는 사회적 현상들에 대한 활발한 연구가 진행되고 있다.
최근에 게임 등 온라인 콘텐츠를 많이 이용하고 아바타나 원격지간 커뮤니케이션 도구들이 많이 생겨나고 있다.
가상 및 네트워크 기술 발전에 따라 비즈니스나 교육 등 다양한 콘텐츠로 확장되고 있다.
실제 원격지에서 공감이나 몰입 등 감성적 커뮤니케이션에 대한 요구도 증가하고 다양한 감성인식 및 평가에 대한 많은 연구들이 진행 되고 있다.

* 감성을 인식하기 위해 생체신호, 영상, 음성 등의 기술을 통해 접근하고 있다.
뇌파(EEG), 심전도(ECG) 등 생체신호를 이용한 감성인식 방법은 생리적 반응을 통해 평가함으로써 보다 객관적이고 정량적인 평가가 가능하다.
하지만 접촉식 센서를 이용하기 때문에 착용에 대한 불편함 및 부담감에 대한 한계점으로 존재한다.
이런 한계점을 극복하기 위해 비접촉 형태의 센싱 기술이 발전하고 있다.
음성의 경우 단어, 말투, 억양 등의 특성이 있어 정확도가 떨어진다는 단점이 있다.
다른 비접촉 형태의 기술인 영상을 이용한 방법은 얼굴 표정이나 제스쳐를 통해 감성을 인식한다.
이 방법은 의도적으로 조절 가능하기 때문에 정량적인 방법으로 감성을 평가하는데 어려움이 있다.
따라서 한계점을 극복하고 의도적인 제어가 불가능한 생리적 반응에 기반 된 감성 인식 및 평가 기술이 필요하다.

* 위(Wii),키넥트(Kinect) 같은 특수한 장치들이 제품으로 출시되고 있다.
이러한 제품들은 특정 하드웨어와 소프트웨어를 동시에 구성해야만 사용가능한 단점이 있다.
최근에는 소프트웨어 기술만 이용한 다양한 인식 기술들이 개발되고 있다.
MIT의 연구에서는 얼굴 피부와 RGB색상 변화와 시간과 공간의 왜곡과 증폭을 통해 심박 정보를 인식하는 기술이 연구되고 있다.
하지만 연구는 조명, 거리 등 환경에 따른 한계점이 존재한다.
따라서 영향을 적게 받는 새로운 기술이 필요하다.

* 인체 미동 기술은 인체 해부학 기관인 전정기관에 메커니즘을 두고 있다.
생리적 반응은 머리 및 상반신의 미세한 움직임을 통해 표현된다.
이런 움직임은 인체의 균형감각을 조절하는 원리에 근거하는 생리적 현상이다.
전정기관은 자율 및 중추신경계 정보를 주고받는 신경로에 위치하며 심혈관계와 호흡계에 영향을 미치는 기관이다.
특히 전정 감정 반사 기능은 신경계의 반응 정보를 각 기관과 주고받는다.
이 때 생리적 반응과 신경 정보들이 미세한 움직임으로 표현되고 감정, 정서, 심리 상태 등에 따라 다르게 반응한다.
이에 근거한 비접촉 형태의 영상 처리기술을 이용해 인체 미동 정보를 추출하여 정략적으로 감성인식을 하고자 한다.

* 본 연구는 비접촉 센싱 방법인 인체의 미동을 이용하여 사회적 관계성에 필요한 공감도를 정략적으로 인식 및 평가하고자 한다.

## 2. 구현 방법
### 2.1 피험자
* 피험자는 Task를 수행하기 위해 한 쌍이 될 수 있도록 하며 성별에 따른 차이를 고려해 남녀 비울을 맞춰 모집하였다.
두 피험자 간에는 어색함을 배제하기 위해 서로 안면이 있는 피험자로 선정하였으며 적극적인 Task를 수행 할 수 있도록 하였다.
피험자는 00대학교 재학생 8명(남자 4, 여자4)이 실험에 참여 하였다.
실험에 참여한 피험자는 심혈 및 신경계에 병력이 없는 자를 모집하였다.
실험 전 수면 및 심혈관계에 미칠 수 있는 카페인, 흡연, 음주 등에 섭취는 금하도록 권고하였다.
모든 피험자에게 실험의 연구목적을 제외한 대략적인 설명을 한 후 진행하였으며 소정의 참가비를 지급하였다.

### 2.2 실험 절차
* 실험은 이성간 차이를 없애기 위해 동성 간에 진행하였으며 피험자는 리더와 팔로워로 분류하였다.
리더는 상대방 뒤편에 있는 자극시스템의 모니터에 나타나는 제시된 얼굴 표정을 직접 보고 Task를 수행하였고 팔로워는 리더의 얼굴을 직접보고 얼굴 표정 실험을 진행하였다.
두 피험자는 서로 역할을 바꿔 4번의 반복을 진행하였다.
리더는 팔로워의 역할 진행시 순서에 따른 효과를 제거하기 위해 랜덤으로 수행 하였다.
Task 수행은 제시된 표정을 따라 하였으며 실험 절차는 Fig. 1과 같다.

### 2.3 실험자극
* 분류된 피험자는 리더와 팔로워로 분류되어 마주보는 형태로 Fig.2 와 같이 배치되었다.
각 리더와 팔로워는 실험 자극과 상대방을 같이 볼 수 있도록 모니터와 함께 배치하였으며 서로 간의 얼굴 표정 및 영상 데이터를 수집할 수 있도록 웹캠을 설치하였다.
미세한 움직임을 측정하기 위해 행동적인 움직임이 제한 된 상태에서 감성적 상태를 사람 간에 가장 잘 표현하고 느낄 수 있는 얼굴 표정 자극을 선정하였다.
에크먼의 6가지 기본 감정을 참고하여 기쁨, 슬픔, 혐오, 두려움, 분노, 놀람에 대한 얼굴 표정 자극을 제시하였다.
자극의 메시지를 받은 피험자는 상대 피험자의 뒷면에 있는 모니터를 통해 6가지 기본 감성 자극을 볼 수 있으며 상대방의 얼굴을 보고 자극을 수행하면 공감으로 분류하고 모니터를 통해 일방적으로 제시된 자극을 보고 수행하면 공감하지 않는 것으로 분류하도록 하였다.

### 2.4 데이터 수집
* 데이터 수집은 각 리더와 팔로워 모두 정면에서 상반신을 촬영 할 수 있도록 하였다.
웹캠은 Microsoft 사의 LifeCam studio를 사용하였다.
카메라 설정은 해상도 640x480, 30fps와 화이트 밸런스 및 포커스 등 자동 조절 기능들은 모두 정지하였다.

### 2.5 데이터 처리
* 인체 미동을 이용하여 데이터를 분석하기 위해 자체적으로 개발한 미동 추출 프로그램을 사용하였으며 Fig. 3과 같다.
프로그램은 각 영상의 프레임별 차이값을 계산하여 한 프레임 간 변화 된 움직임의 양을 계산하는 것으로 현재와 이전의 움직임 정보를 추출하여 초당 30Hz의 Raw 데이터가 된다.
선행 연구에 따르면 움직임의 크기에 따라 주파수 성분으로 추출 할 수 있음으로 작은 움직임과 큰 움직임 차이를 고려해 적용하였다.
30 Hz의 미동 데이터는 초당 0.5Hz, 1Hz, 3Hz, 5Hz, 15Hz 형태로 주파수 성분에 따라 움직임의 크기 별로 데이터를 추출하였고 프레임 내의 전체 움직임을 평균으로 변환해 저장하였다.
(1)의 화면은 피험자의 실시간 얼굴 영상을 표시하는 화면이며, (2)의 화면은 실제 피험자의 움직임이 발생한 정보만 표시하는 영역으로 그 데이터는 (4)화면과 같이 나타나게 된다.
(3)화면의 경우 잘 보이지 않는 미세한 움직임의 데이터를 실시간으로 추출 할 때 나타나는 움직임 양의 Raw data를 표시하는 화면이다.

### 2.6 데이터 분석
* 자극 시스템의 표정을 보고 수행하는 공감하지 않는 그룹과 상대방의 얼굴을 직접 보고 수행하는 공감하는 그룹으로 분류하였다.
분류된 그룹은 각 움직임 크기별로 추출될 수 있는 정보에 따라 움직임 양, 움직임 양의 변화량, 동시 실험을 진행한 피험자들 간에 움직임의 동조현상을 분석하였다.
추출 된 데이터 모두 정규성을 따르지 않아 비모수 검정을 실시하였다.
공감과 비공감 그룹 간 차이를 비교하기 위해 움직임 양 및 움직임 변화량 데이터는 두 집단의 독립성을 보장되지 않고 정규성을 따르지 않아 만-휘트니 분석을 실시하였다.
또한 두 사람 간의 움직임에 대한 동기화 정도를 확인하기 위해 Correlation 분석을 진행하였다.
데이터 분석은 SPSS ver17k를 사용하여 통계 검증을 실시하였으며 데이터 샘플은 G Power ver 3.1.7을 이용하여 샘플 수를 충족 확인 후 데이터 분석을 진행하였다.


## 3. 결과
### 3.1 움직임 양
* 6가지 얼굴 표정 Task를 수행한 구간을 각 주파수 별로 추출하였다.
분석 결과 0.5Hz에서 공감과 비공감을 비교 결과 Fig.4 와 같이 통계적으로 유의한 차이를 보였다.
1Hz에서 공감과 비공감을 비교 결과 

### 3.2 움직임 양의 변화량


### 3.3 동조현상


## 4. 결론
* 본 연구는 사회관계성 중에 하나인 공감도를 인체 미동이라는 비접촉 센싱 기법을 이용하여 확인하였다.
실험은 남녀 대학생 피험자 8명을 대상으로 에키먼의 6가시 표정을 수행하는 실험을 진행하였다.
공감한 그룹과 비공감 그룹으로 피험자를 분류하여 6가지 표정을 수행하는 동안 데이터를 측정 할 수 있도록 하였다.
공감과 비공감 일 때 인체 반응ㅇ을 모니터링 하는 형태로 실험이 수행되었다.

* 실험 데이터 분석은 인체 미동을 통해 얻어진 데이터를 각 6가지 표정 Task 별 데이터를 수집하였다.
1초 동안 수집된 30fps 영상에서 각 0.5Hz, 1Hz, 3Hz, 5Hz, 15Hz로 움직임 양을 구분하여 각 Task 별 움직임의 데이터를 추출하였다.
움직임의 평균과 변화량을 분석하였다.
또한 공감한 사람과 비공감한 사람 간 움직임에 동조현상을 비교하여 인체에 움직임이 어떻게 반영되어 나타나는지 분석하였다.

* 미동의 패턴 분석 중에서 먼저 움직임의 평균은 6가지 얼굴 표정을 지어 나온 평균적인 움직임 야ㅑㅇ의 통계 분석 결과 유의한 차이를 보였다.
또한 움직임의 변화량도 동일하게 통계적인 차이를 보였다.
이는 공감을 할 떄의 움직임 양이 적고 움직임의 변화 정도 또한 적다고 볼 수 있다.
반대로 공감하지 않을 때는 움직임의 양이 크며 그 변화의 정도가 큰 것으로 볼 수 있다.
두 피험자간의 동조현상에 대한 데이터 비교 결과 공감 할 때가 공감하지 않을 때 보다 두 피험자 간의 동조 현상이 높은 것으로 확인되었다.

* 연구 결과 타인과 공감이 되었을 때 해당 Task의 몰임과 집중하게 되어 움직임의 정도가 줄어들고 반대로 공감하지 못하였을 때는 집중하지 못하게 됨에 따라 산만해지며 움직임에 양과 변화정도가 커지는 것으로 해석할 수 있다.

* 공감도 평가 시 접촉형 센싱 방법이 아닌 일반 웹카메라를 활용하여 비접촉형 센싱 기법을 활용하였다.
따라서 센서 착용의 부담감 및 불편한 요소를 최소화 하였다.
이러한 방법을 활용하면 다양한 공간과 기기에서 간단한 동영상 촬영만으로 공감도를 평가할 수 있다.

* 가상 또는 원격의 도구를 활용한 커뮤니케이션은 주로 언어적 표현을 이용하며 의미 전달은 되지만 느낌과 같은 비언어적 표현은 전달의 오류가 생기는 경우가 있다.
하지만 커뮤니케이션에 있어 서로 공감과 같은 감성 인식 기술을 적용하면 커뮤니케이션의 오류를 줄일 수 있고 생리적 반응에 의거한 정략적 인식 기술이기 때문에 그 정확도나 활용의 가치가 높을 것으로 예상된다.

* 본 연구에서는 시간적, 공간적, 물질적, 신체적 부담을 최소화 시킨 인체 미동 기술을 이용하여 공감도 평가를 확인하였다.
하지만 본 연구는 이러한 비접촉형 방식의 감성인식 방법에 대한 초기 연구 중 하나로써 주변환경이나 빛 등의 외부요인을 최소화하여 정확도를 높이기 위한 추가 연구가 필요하고 추후 다양한 조건 및 더 많은 실험을 통해 정략적 성과를 확보하기 위한 노력이 필요하다.

* 기술발전에 따라 시공간 제약이 사라지고 다양한 공간에서 감성적 커뮤니케이션을 통한 감성인식 연구들이 증가하고 있다.
따라서 본 연구는 감성을 정량적으로 평가 하능한 방법으로 감성 인식 방법을 넓히는데 있어 의의가 있다.
